{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa2f7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\ml-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ML Challenge 2025: Full Pipeline Initializing (PyTorch Version) ---\n",
      "PyTorch Version: 2.5.1\n",
      "Timm Version: 1.0.20\n",
      "✅ Success! Found GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   PyTorch will use the GPU for image processing.\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Step 1: Loading original CSV data ---\n",
      "CSV data loaded successfully.\n",
      "\n",
      "--- Step 2: Processing text features ---\n",
      "IPQ feature created.\n",
      "Text vectorization complete.\n",
      "\n",
      "--- Step 3: Processing image features ---\n",
      "Found pre-computed image features. Loading from disk.\n",
      "Shape of training image features: (75000, 1280)\n",
      "\n",
      "--- Step 4: Combining features and creating validation set ---\n",
      "Original training data shape: (75000, 11281)\n",
      "New training set shape: (60000, 11281)\n",
      "Validation set shape: (15000, 11281)\n",
      "\n",
      "--- Step 5: Training the final LightGBM model ---\n",
      "Model training complete!\n",
      "\n",
      "--- Evaluating model performance on the validation set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\ml-env\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation SMAPE Score: 53.8563%\n",
      "\n",
      "--- Step 6: Generating final submission file ---\n",
      "Submission file created successfully at: dataset/submission_final_local_pytorch.csv\n",
      "   sample_id  price\n",
      "0     100179  14.48\n",
      "1     245611  21.33\n",
      "2     146263  17.84\n",
      "3      95658   6.63\n",
      "4      36806  16.01\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# ML Challenge 2025: Smart Product Pricing\n",
    "# Full End-to-End Pipeline with Validation\n",
    "#\n",
    "# >> PyTorch Version <<\n",
    "#\n",
    "# This single script handles the entire workflow:\n",
    "# 1. Text Feature Engineering\n",
    "# 2. Parallel Image Downloading & Feature Extraction\n",
    "# 3. Combined Model Training & SMAPE Validation\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "# ML/DL Libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split ## NEW ## Import for validation split\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import torch\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "\n",
    "print(\"--- ML Challenge 2025: Full Pipeline Initializing (PyTorch Version) ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Timm Version: {timm.__version__}\")\n",
    "\n",
    "# === GPU Verification ===\n",
    "is_gpu_available = torch.cuda.is_available()\n",
    "if is_gpu_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"✅ Success! Found GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\"   PyTorch will use the GPU for image processing.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ Warning: No GPU found.\")\n",
    "    print(\"   PyTorch will run on the CPU, which will be very slow for image processing.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# === Main Configuration ===\n",
    "DATA_PATH = 'dataset/'\n",
    "IMAGE_DIR = os.path.join(DATA_PATH, 'product_images/')\n",
    "FEATURES_DIR = os.path.join(DATA_PATH, 'features/')\n",
    "\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "## NEW ## Function to calculate SMAPE score\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "\n",
    "# === Strategy 1: Text Feature Engineering Functions ===\n",
    "def extract_ipq(text):\n",
    "    \"\"\"Extracts the Item Pack Quantity (IPQ) from text.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    patterns = [\n",
    "        r'pack of (\\d+)', r'(\\d+)\\s*x\\s', r'(\\d+)\\s*count', r'(\\d+)\\s*ct',\n",
    "        r'(\\d+)\\s*pack', r'(\\d+)\\s*pcs', r'(\\d+)\\s*pk', r'(\\d+)\\s*ea'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return 1\n",
    "\n",
    "\n",
    "# === Strategy 2: Image Processing Functions ===\n",
    "def download_single_image(args):\n",
    "    \"\"\"Helper function to download one image; designed for multithreading.\"\"\"\n",
    "    image_url, filename = args\n",
    "    if not os.path.exists(filename):\n",
    "        try:\n",
    "            response = requests.get(image_url, timeout=20)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            img.convert('RGB').save(filename, \"JPEG\")\n",
    "            return \"Downloaded\"\n",
    "        except requests.exceptions.RequestException:\n",
    "            return \"Failed\"\n",
    "        except Exception:\n",
    "            return \"Failed\"\n",
    "    else:\n",
    "        return \"Skipped\"\n",
    "\n",
    "def download_images(df, save_dir):\n",
    "    \"\"\"Downloads images from URLs in a dataframe in parallel using multithreading.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Checking and downloading images to {save_dir} using multiple threads...\")\n",
    "    tasks = []\n",
    "    for index, row in df.iterrows():\n",
    "        filename = os.path.join(save_dir, f\"{row['sample_id']}.jpg\")\n",
    "        tasks.append((row['image_link'], filename))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        results = list(tqdm(executor.map(download_single_image, tasks), total=len(tasks), desc=\"Downloading images\"))\n",
    "    print(f\"Download process complete. Downloaded: {results.count('Downloaded')}, Skipped: {results.count('Skipped')}, Failed: {results.count('Failed')}\")\n",
    "\n",
    "def extract_image_features(image_dir, df, model, device):\n",
    "    \"\"\"Extracts image embeddings using a pre-trained PyTorch CNN.\"\"\"\n",
    "    IMG_SIZE = 224\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    features = []\n",
    "    model.eval()\n",
    "    print(\"Extracting image features with PyTorch...\")\n",
    "    with torch.no_grad():\n",
    "        for sample_id in tqdm(df['sample_id'], desc=\"Extracting features\"):\n",
    "            img_path = os.path.join(image_dir, f\"{sample_id}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "                    feature = model(img_tensor)\n",
    "                    features.append(feature.cpu().numpy().flatten())\n",
    "                except Exception:\n",
    "                    features.append(np.zeros(model.num_features))\n",
    "            else:\n",
    "                features.append(np.zeros(model.num_features))\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# === Main Execution Block ===\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- Step 1: Load original data ---\n",
    "    print(\"\\n--- Step 1: Loading original CSV data ---\")\n",
    "    train_df = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "    test_df = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "    print(\"CSV data loaded successfully.\")\n",
    "\n",
    "    # --- Step 2: Process Text Features ---\n",
    "    print(\"\\n--- Step 2: Processing text features ---\")\n",
    "    train_df['ipq'] = train_df['catalog_content'].apply(extract_ipq)\n",
    "    test_df['ipq'] = test_df['catalog_content'].apply(extract_ipq)\n",
    "    print(\"IPQ feature created.\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "    X_train_text = vectorizer.fit_transform(train_df['catalog_content'])\n",
    "    X_test_text = vectorizer.transform(test_df['catalog_content'])\n",
    "    print(\"Text vectorization complete.\")\n",
    "\n",
    "    # --- Step 3: Process Image Features (Download & Extract) ---\n",
    "    print(\"\\n--- Step 3: Processing image features ---\")\n",
    "    train_features_path = os.path.join(FEATURES_DIR, 'train_image_features.npy')\n",
    "    test_features_path = os.path.join(FEATURES_DIR, 'test_image_features.npy')\n",
    "\n",
    "    if os.path.exists(train_features_path) and os.path.exists(test_features_path):\n",
    "        print(\"Found pre-computed image features. Loading from disk.\")\n",
    "        train_image_features = np.load(train_features_path)\n",
    "        test_image_features = np.load(test_features_path)\n",
    "    else:\n",
    "        print(\"Pre-computed features not found. Running the full image pipeline...\")\n",
    "        # 3a. Download images\n",
    "        download_images(train_df, os.path.join(IMAGE_DIR, 'train/'))\n",
    "        download_images(test_df, os.path.join(IMAGE_DIR, 'test/'))\n",
    "        print(\"Image download complete.\")\n",
    "\n",
    "        # 3b. Extract features\n",
    "        print(f\"Loading EfficientNetB0 model onto device: {device.type}\")\n",
    "        cnn_model = timm.create_model(\n",
    "            'efficientnet_b0', pretrained=True, num_classes=0\n",
    "        ).to(device)\n",
    "        train_image_features = extract_image_features(os.path.join(IMAGE_DIR, 'train/'), train_df, cnn_model, device)\n",
    "        test_image_features = extract_image_features(os.path.join(IMAGE_DIR, 'test/'), test_df, cnn_model, device)\n",
    "        \n",
    "        # 3c. Save features\n",
    "        np.save(train_features_path, train_image_features)\n",
    "        np.save(test_features_path, test_image_features)\n",
    "        print(\"Image features extracted and saved to disk for future runs.\")\n",
    "\n",
    "    print(f\"Shape of training image features: {train_image_features.shape}\")\n",
    "\n",
    "    # --- Step 4: Combine All Features and Create Validation Set --- ## MODIFIED ##\n",
    "    print(\"\\n--- Step 4: Combining features and creating validation set ---\")\n",
    "    train_ipq_sparse = csr_matrix(train_df['ipq'].values.reshape(-1, 1))\n",
    "    test_ipq_sparse = csr_matrix(test_df['ipq'].values.reshape(-1, 1))\n",
    "    train_image_sparse = csr_matrix(train_image_features)\n",
    "    test_image_sparse = csr_matrix(test_image_features)\n",
    "\n",
    "    X_train_combined = hstack([X_train_text, train_ipq_sparse, train_image_sparse])\n",
    "    X_test_combined = hstack([X_test_text, test_ipq_sparse, test_image_sparse])\n",
    "    y_train_full = train_df['price']\n",
    "\n",
    "    ## NEW ## Split data into training and validation sets (80/20 split)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_combined, y_train_full, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Original training data shape: {X_train_combined.shape}\")\n",
    "    print(f\"New training set shape: {X_train.shape}\")\n",
    "    print(f\"Validation set shape: {X_val.shape}\")\n",
    "\n",
    "    # --- Step 5: Train Model and Validate --- ## MODIFIED ##\n",
    "    print(\"\\n--- Step 5: Training the final LightGBM model ---\")\n",
    "    lgb_params = {\n",
    "        'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 3000,\n",
    "        'learning_rate': 0.02, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1,\n",
    "        'num_leaves': 40, 'verbose': -1, 'n_jobs': -1, 'seed': 42\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**lgb_params)\n",
    "    \n",
    "    ## MODIFIED ## Train on the new, smaller training set\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete!\")\n",
    "\n",
    "    ## NEW ## Evaluate model performance on the validation set\n",
    "    print(\"\\n--- Evaluating model performance on the validation set ---\")\n",
    "    val_predictions = model.predict(X_val)\n",
    "    smape_score = calculate_smape(y_val, val_predictions)\n",
    "    print(f\"✅ Validation SMAPE Score: {smape_score:.4f}%\")\n",
    "\n",
    "    # --- Step 6: Generate Submission File ---\n",
    "    print(\"\\n--- Step 6: Generating final submission file ---\")\n",
    "    predictions = model.predict(X_test_combined)\n",
    "    predictions[predictions < 0] = 0\n",
    "    predictions = np.round(predictions, 2)\n",
    "\n",
    "    submission_df = pd.DataFrame({'sample_id': test_df['sample_id'], 'price': predictions})\n",
    "    submission_path = os.path.join(DATA_PATH, 'submission_final_local_pytorch.csv')\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Submission file created successfully at: {submission_path}\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b18c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
